{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11278656,"sourceType":"datasetVersion","datasetId":7051312}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install -r /kaggle/input/requirements-txt/requirements.txt\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:54:46.859791Z","iopub.execute_input":"2025-04-04T19:54:46.860186Z","iopub.status.idle":"2025-04-04T19:54:52.199915Z","shell.execute_reply.started":"2025-04-04T19:54:46.860160Z","shell.execute_reply":"2025-04-04T19:54:52.198844Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 4)) (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 5)) (0.12.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 6)) (4.67.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.3.1)\nCollecting tree-sitter (from -r /kaggle/input/requirements-txt/requirements.txt (line 10))\n  Downloading tree_sitter-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\nCollecting tree-sitter-python (from -r /kaggle/input/requirements-txt/requirements.txt (line 11))\n  Downloading tree_sitter_python-0.23.6-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nCollecting tree-sitter-java (from -r /kaggle/input/requirements-txt/requirements.txt (line 12))\n  Downloading tree_sitter_java-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 15)) (1.2.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 16)) (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 17)) (1.2.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 18)) (2.5.1+cu121)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 19)) (0.14.0)\nCollecting evaluate (from -r /kaggle/input/requirements-txt/requirements.txt (line 22))\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 23)) (0.19.1)\nRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 26)) (3.1.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 29)) (0.45.1)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/requirements-txt/requirements.txt (line 32)) (0.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/input/requirements-txt/requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/input/requirements-txt/requirements.txt (line 3)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/input/requirements-txt/requirements.txt (line 3)) (2025.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /kaggle/input/requirements-txt/requirements.txt (line 4)) (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (6.0.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /kaggle/input/requirements-txt/requirements.txt (line 15)) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /kaggle/input/requirements-txt/requirements.txt (line 15)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /kaggle/input/requirements-txt/requirements.txt (line 15)) (3.5.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /kaggle/input/requirements-txt/requirements.txt (line 16)) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /kaggle/input/requirements-txt/requirements.txt (line 16)) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /kaggle/input/requirements-txt/requirements.txt (line 16)) (0.4.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /kaggle/input/requirements-txt/requirements.txt (line 17)) (5.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (3.20.3)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (2.11.0a2)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (75.1.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask->-r /kaggle/input/requirements-txt/requirements.txt (line 26)) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask->-r /kaggle/input/requirements-txt/requirements.txt (line 26)) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask->-r /kaggle/input/requirements-txt/requirements.txt (line 26)) (1.9.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (1.18.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (4.0.11)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /kaggle/input/requirements-txt/requirements.txt (line 18)) (3.0.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /kaggle/input/requirements-txt/requirements.txt (line 9)) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r /kaggle/input/requirements-txt/requirements.txt (line 23)) (5.0.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->-r /kaggle/input/requirements-txt/requirements.txt (line 2)) (2024.2.0)\nDownloading tree_sitter-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m574.3/574.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tree_sitter_python-0.23.6-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tree_sitter_java-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tree-sitter-python, tree-sitter-java, tree-sitter, evaluate\nSuccessfully installed evaluate-0.4.3 tree-sitter-0.24.0 tree-sitter-java-0.23.5 tree-sitter-python-0.23.6\nFri Apr  4 19:54:52 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, Subset\n\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom peft import LoraConfig, get_peft_model, TaskType\n\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\n\n# WandB\nimport wandb\n\n# AST\nfrom tree_sitter import Language, Parser\nimport tree_sitter_python\nimport tree_sitter_java\n\n## AST Graphing\nimport graphviz\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Datasets\nfrom pathlib import Path\nfrom datasets import load_dataset, load_from_disk, DatasetDict, concatenate_datasets\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:54:55.030766Z","iopub.execute_input":"2025-04-04T19:54:55.031076Z","iopub.status.idle":"2025-04-04T19:54:55.765894Z","shell.execute_reply.started":"2025-04-04T19:54:55.031050Z","shell.execute_reply":"2025-04-04T19:54:55.764917Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"markdown","source":"## Python Data","metadata":{}},{"cell_type":"code","source":"# Python loading\npython_dataset = DatasetDict({\n    'train': load_dataset('code_search_net', 'python', split='train[:15000]', trust_remote_code=True),\n    'validation': load_dataset('code_search_net', 'python', split='validation[:2000]', trust_remote_code=True),\n    'test': load_dataset('code_search_net', 'python', split='test[:2000]', trust_remote_code=True)\n})\n\npython_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:55:17.391794Z","iopub.execute_input":"2025-04-04T19:55:17.392507Z","iopub.status.idle":"2025-04-04T19:57:07.577858Z","shell.execute_reply.started":"2025-04-04T19:55:17.392473Z","shell.execute_reply":"2025-04-04T19:57:07.577042Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13cb8d141bdc4f12a3005ef0719d31d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"code_search_net.py:   0%|          | 0.00/8.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"870d88e4e2da493181ab0b0b9f419381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"python.zip:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"380fc5efab1f428bab0bcdf25c877c6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3585159d927c4b7dbe7fc3d9aa79109f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4990565af674b6e9c7826db199c748d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07d37519c0843ad980bc1c4059e5e9c"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 15000\n    })\n    validation: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Java Data","metadata":{}},{"cell_type":"code","source":"# Java loading\njava_dataset = DatasetDict({\n    'train': load_dataset('code_search_net', 'java', split='train[:15000]', trust_remote_code=True),\n    'validation': load_dataset('code_search_net', 'java', split='validation[:2000]', trust_remote_code=True),\n    'test': load_dataset('code_search_net', 'java', split='test[:2000]', trust_remote_code=True)\n})\n\njava_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:57:07.579236Z","iopub.execute_input":"2025-04-04T19:57:07.579555Z","iopub.status.idle":"2025-04-04T19:59:04.798697Z","shell.execute_reply.started":"2025-04-04T19:57:07.579530Z","shell.execute_reply":"2025-04-04T19:59:04.797944Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"java.zip:   0%|          | 0.00/1.06G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8adc0a3f274fec9aa6905b2676f1b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/454451 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e9d7c78013b44d1a773a9300a80b83f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/26909 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45b1d93a8944138b71d366e27e47e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/15328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89993ed7be2946e7b912b0583e274b49"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 15000\n    })\n    validation: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Debug and Test modes","metadata":{}},{"cell_type":"code","source":"# set to False for full training config\ndebug = False\n# set tp True for enabling testing blocks\ntest_run = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:59:08.616676Z","iopub.execute_input":"2025-04-04T19:59:08.617022Z","iopub.status.idle":"2025-04-04T19:59:08.621090Z","shell.execute_reply.started":"2025-04-04T19:59:08.616991Z","shell.execute_reply":"2025-04-04T19:59:08.620214Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Concatenation","metadata":{}},{"cell_type":"code","source":"combined_dataset = DatasetDict({\n    'train': concatenate_datasets([python_dataset['train'], java_dataset['train']]),\n    'validation': concatenate_datasets([python_dataset['validation'], java_dataset['validation']]),\n    'test': concatenate_datasets([python_dataset['test'], java_dataset['test']])\n})\n\nif debug:\n    combined_dataset[\"train\"] = combined_dataset[\"train\"].select(range(200))\n    combined_dataset[\"validation\"] = combined_dataset[\"validation\"].select(range(50))\n    combined_dataset[\"test\"] = combined_dataset[\"test\"].select(range(50))\n\ncombined_dataset['train'] = combined_dataset['train'].shuffle(seed=42)\ncombined_dataset['validation'] = combined_dataset['validation'].shuffle(seed=42)\ncombined_dataset['test'] = combined_dataset['test'].shuffle(seed=42)\n\ncombined_dataset['train']['func_code_string'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:59:11.400169Z","iopub.execute_input":"2025-04-04T19:59:11.400498Z","iopub.status.idle":"2025-04-04T19:59:11.618485Z","shell.execute_reply.started":"2025-04-04T19:59:11.400469Z","shell.execute_reply":"2025-04-04T19:59:11.617673Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'def add_vip(\\n            self,\\n            id,\\n            real_name_sufixo,\\n            id_vlan,\\n            descricao_vlan,\\n            id_vlan_real,\\n            descricao_vlan_real,\\n            balanceadores,\\n            id_healthcheck_expect,\\n            finalidade,\\n            cliente,\\n            ambiente,\\n            cache,\\n            metodo_bal,\\n            persistencia,\\n            healthcheck_type,\\n            healthcheck,\\n            timeout,\\n            host,\\n            maxcon,\\n            dsr,\\n            bal_ativo,\\n            transbordos,\\n            portas,\\n            real_maps,\\n            id_requisicao_vip,\\n            areanegocio=\\'Orquestra\\',\\n            nome_servico=\\'Orquestra\\',\\n            l7_filter=None,\\n            reals_prioritys=None,\\n            reals_weights=None):\\n        \"\"\"Adiciona um VIP na lista de VIPs para operação de inserir/alterar um grupo virtual.\\n\\n        Os parâmetros abaixo somente são necessários para a operação de alteração:\\n\\n            - \\'real_maps\\': Deverá conter os reals atualmente criados para a requisição de VIP.\\n            - \\'id_requisicao_vip\\': O identificador da requisição que deverá ser alterada.\\n\\n        Os parâmetros abaixo somente são necessários para a operação de inserção:\\n\\n            - \\'id_vlan\\': Identificador da VLAN para criar o IP do VIP.\\n            - \\'descricao_vlan\\': Descrição do IP do VIP.\\n            - balanceadores: Lista com os identificadores dos balanceadores que serão associados ao IP do VIP.\\n\\n        :param id: Identificador do VIP utilizado pelo sistema de orquestração.\\n        :param real_name_sufixo: Sufixo utilizado para criar os reals_names dos equipamentos na requisição de VIP.\\n        :param id_vlan: Identificador da VLAN para criar um IP para o VIP.\\n        :param descricao_vlan: Descrição do IP que será criado para o VIP.\\n        :param id_vlan_real: Identificador da VLAN para criar os IPs dos equipamentos no VIP.\\n        :param descricao_vlan_real: Descrição dos IPs que serão criados para os equipamentos no VIP.\\n        :param balanceadores: Lista com os identificadores dos balanceadores que serão associados ao IP do VIP.\\n        :param id_healthcheck_expect: Identificador do healthcheck_expect para criar a requisição de VIP.\\n        :param finalidade: Finalidade da requisição de VIP.\\n        :param cliente: Cliente da requisição de VIP.\\n        :param ambiente: Ambiente da requisição de VIP.\\n        :param cache: Cache da requisição de VIP.\\n        :param metodo_bal: Método de balanceamento da requisição de VIP.\\n        :param persistencia: Persistência da requisição de VIP.\\n        :param healthcheck_type: Healthcheck_type da requisição de VIP.\\n        :param healthcheck: Healthcheck da requisição de VIP.\\n        :param timeout: Timeout da requisição de VIP.\\n        :param host: Host da requisição de VIP.\\n        :param maxcon: Máximo número de conexão da requisição de VIP.\\n        :param dsr: DSR da requisição de VIP.\\n        :param bal_ativo: Balanceador ativo da requisição de VIP.\\n        :param transbordos: Lista com os IPs dos transbordos da requisição de VIP.\\n        :param portas: Lista com as portas da requisição de VIP.\\n        :param real_maps: Lista dos mapas com os dados dos reals da requisição de VIP.\\n            Cada mapa deverá ter a estrutura: {\\'real_name\\':< real_name>, \\'real_ip\\':< real_ip>}\\n        :param id_requisicao_vip: Identificador da requisição de VIP para operação de alterar um\\n            grupo virtual.\\n        :param areanegocio: Área de negócio para a requisição de VIP (é utilizado \\'Orquestra\\' caso seja None).\\n        :param nome_servico: Nome do serviço para a requisição de VIP (é utilizado \\'Orquestra\\' caso seja None).\\n        :param l7_filter: Filtro L7 para a requisição de VIP.\\n        :param reals_prioritys: Lista dos dados de prioridade dos reals da requisição de VIP (lista de zeros, caso seja None).\\n        :param reals_weights: Lista dos dados de pesos dos reals da requisição de VIP (lista de zeros, caso seja None).\\n\\n        :return: None\\n        \"\"\"\\n        vip_map = dict()\\n\\n        vip_map[\\'id\\'] = id\\n        # Causa erro na hora de validar os nomes de equipamentos (real servers)\\n        #vip_map[\\'real_name_sufixo\\'] = real_name_sufixo\\n        vip_map[\\'ip_real\\'] = {\\n            \\'id_vlan\\': id_vlan_real,\\n            \\'descricao\\': descricao_vlan_real}\\n        vip_map[\\'ip\\'] = {\\'id_vlan\\': id_vlan, \\'descricao\\': descricao_vlan}\\n        vip_map[\\'balanceadores\\'] = {\\'id_equipamento\\': balanceadores}\\n        vip_map[\\'id_healthcheck_expect\\'] = id_healthcheck_expect\\n        vip_map[\\'finalidade\\'] = finalidade\\n        vip_map[\\'cliente\\'] = cliente\\n        vip_map[\\'ambiente\\'] = ambiente\\n        vip_map[\\'cache\\'] = cache\\n        vip_map[\\'metodo_bal\\'] = metodo_bal\\n        vip_map[\\'persistencia\\'] = persistencia\\n        vip_map[\\'healthcheck_type\\'] = healthcheck_type\\n        vip_map[\\'healthcheck\\'] = healthcheck\\n        vip_map[\\'timeout\\'] = timeout\\n        vip_map[\\'host\\'] = host\\n        vip_map[\\'maxcon\\'] = maxcon\\n        vip_map[\\'dsr\\'] = dsr\\n        # Nao sao mais utilizados (bal_ativo e transbordos)\\n        #vip_map[\\'bal_ativo\\'] = bal_ativo\\n        #vip_map[\\'transbordos\\'] = {\\'transbordo\\': transbordos}\\n        vip_map[\\'portas_servicos\\'] = {\\'porta\\': portas}\\n        vip_map[\\'reals\\'] = {\\'real\\': real_maps}\\n        vip_map[\\'areanegocio\\'] = areanegocio\\n        vip_map[\\'nome_servico\\'] = nome_servico\\n        vip_map[\\'l7_filter\\'] = l7_filter\\n\\n        if reals_prioritys is not None:\\n            vip_map[\\'reals_prioritys\\'] = {\\'reals_priority\\': reals_prioritys}\\n        else:\\n            vip_map[\\'reals_prioritys\\'] = None\\n\\n        if metodo_bal.upper() == \\'WEIGHTED\\':\\n            if reals_weights is not None:\\n                vip_map[\\'reals_weights\\'] = {\\'reals_weight\\': reals_weights}\\n            else:\\n                vip_map[\\'reals_weights\\'] = None\\n\\n        if id_requisicao_vip is not None:\\n            vip_map[\\'requisicao_vip\\'] = {\\'id\\': id_requisicao_vip}\\n\\n        self.lista_vip.append(vip_map)'"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# AST Integration, Masking & Preprocessing Functions","metadata":{}},{"cell_type":"code","source":"def mask_func_name(code_str: str, func_name: str, lang: str) -> str:\n    lang = lang.lower()\n\n    if lang == 'python':\n        pattern = rf\"(def\\s+)({re.escape(func_name)})(\\s*\\()\"\n        return re.sub(pattern, r\"\\1<extra_id_0>\\3\", code_str, count=1)\n    \n    elif lang == 'java':\n        pattern = rf\"(?<!\\w){re.escape(func_name)}(?=\\s*\\()\"\n        return re.sub(pattern, \"<extra_id_0>\", code_str, count=1)\n\n    else:\n        return code_str\n\ndef test_real_python_samples(dataset, num_samples=3):\n    print(\"=== REAL PYTHON SAMPLES ===\")\n    \n    for i in range(num_samples):\n        full_func_name = dataset['train'][i]['func_name'] \n        method_name = full_func_name.split('.')[-1] \n        code = dataset['train'][i]['func_code_string']\n        \n        print(f\"--- Sample #{i} ---\")\n        print(f\"Original Function Name: {full_func_name}\")\n        print(\"\\nOriginal Code:\\n\", code)\n        print(\"\\nMasked Code:\\n\", mask_func_name(code, method_name, lang=\"python\"))\n        print(\"=\" * 100 + \"\\n\")\n\ndef test_real_java_samples(dataset, num_samples=3):\n    print(\"=== REAL JAVA SAMPLES ===\")\n    \n    for i in range(num_samples):\n        full_func_name = dataset['train'][i]['func_name']\n        method_name = full_func_name.split('.')[-1]\n        code = dataset['train'][i]['func_code_string']\n        \n        print(f\"--- Sample #{i} ---\")\n        print(f\"Original Function Name: {full_func_name}\")\n        print(\"\\nOriginal Code:\\n\", code)\n        print(\"\\nMasked Code:\\n\", mask_func_name(code, method_name, lang=\"java\"))\n        print(\"=\" * 100 + \"\\n\")\n\n\ndef inspect_samples(dataset, lang: str, num_samples: int = 5):\n    print(f\"\\n=== {lang.upper()} SAMPLE VERIFICATION ===\\n\")\n    for i in range(num_samples):\n        sample = dataset['train'][i]\n        code = sample['func_code_string']\n        full_name = sample['func_name']\n        method_name = full_name.split('.')[-1]\n\n        masked_code = mask_func_name(code, method_name, lang)\n        tokens = tokenizer.tokenize(masked_code)\n\n        print(f\"--- Sample #{i} ---\")\n        print(f\"Original Function Name: {full_name}\")\n        print(\"\\nOriginal Code:\\n\", code)\n        print(\"\\nMasked Code:\\n\", masked_code)\n        print(\"\\nTokenized Input:\\n\", tokens)\n        print(\"=\" * 100)\n\ndef preprocess(examples):\n    combined_inputs = []\n    combined_labels = []\n    \n    # Iterate over each example\n    for code, target, lang in zip(examples['func_code_string'], examples['func_name'], examples['language']):\n         # Extract method name (in case it's fully qualified like Class.method)\n        method_name = target.split('.')[-1]\n        # Mask function name in definition\n        masked_code = mask_func_name(code, method_name, lang)\n\n        combined_inputs.append(masked_code)\n        combined_labels.append(method_name) # Extract the method name from the full path\n    \n    # Tokenize the combined input and targets\n    model_inputs = tokenizer(combined_inputs, max_length=1024, truncation=True, padding='max_length')\n    tokenized_labels = tokenizer(combined_labels, max_length=50, truncation=True, padding='max_length')\n    \n    model_inputs['labels'] = tokenized_labels['input_ids']\n    return model_inputs\n\n\nif debug:\n    # Run both inspections\n    inspect_samples(python_dataset, lang=\"python\", num_samples=5)\n    inspect_samples(java_dataset, lang=\"java\", num_samples=5)\n    \n    # Run the test\n    test_real_java_samples(java_dataset, num_samples=5)\n    test_real_python_samples(python_dataset, num_samples=5)\n    \n    print(\"<extra_id_0>\" in tokenizer.get_vocab())\n    print(\"<mask>\" in tokenizer.get_vocab())\n    print(\"Token ID for <extra_id_0>:\", tokenizer.convert_tokens_to_ids(\"<extra_id_0>\"))\n    print(\"All special tokens:\", tokenizer.special_tokens_map)\n    print(\"Additional special tokens:\", tokenizer.additional_special_tokens)\n\n\n\n# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:59:18.332759Z","iopub.execute_input":"2025-04-04T19:59:18.333052Z","iopub.status.idle":"2025-04-04T19:59:20.052088Z","shell.execute_reply.started":"2025-04-04T19:59:18.333029Z","shell.execute_reply":"2025-04-04T19:59:20.051408Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3326b69bc8845cfa26884c69d002090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b67e52d557b4b74b25f392c27b05538"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f127f4b1aab845efaf9c1d1f8c902458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd0921d6e1e94b198f698307588f288d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5841ba6c3fd9484692714dc8db8d84d7"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = combined_dataset.map(preprocess, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:59:26.552913Z","iopub.execute_input":"2025-04-04T19:59:26.553266Z","iopub.status.idle":"2025-04-04T20:00:00.866188Z","shell.execute_reply.started":"2025-04-04T19:59:26.553236Z","shell.execute_reply":"2025-04-04T20:00:00.865445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480595eac36c4f3b892b69017fa466ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bec846d344a4e74b9705baf86802bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df0dbce758134a9e884da54d93a13d04"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"if debug:\n    num_samples_to_show = 5\n    \n    for idx in range(num_samples_to_show):\n        print(f\"\\n===== Sample {idx + 1} =====\")\n    \n        # Print decoded input (with masking, i.e., function body with <extra_id_0>)\n        input_ids = tokenized_dataset[\"train\"][idx][\"input_ids\"]\n        decoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\n        print(\"▶️ Masked Input Code:\\n\", decoded_input)\n    \n        # Print decoded label (method name target)\n        label_ids = tokenized_dataset[\"train\"][idx][\"labels\"]\n        decoded_label = tokenizer.decode(\n            [id for id in label_ids if id != tokenizer.pad_token_id],\n            skip_special_tokens=True\n        )\n        print(\"🎯 Target Method Name:\", decoded_label)\n    \n        # Optional: show original method name from combined dataset (if available)\n        if \"func_name\" in combined_dataset[\"train\"].features:\n            original_name = combined_dataset[\"train\"][idx][\"func_name\"]\n            print(\"🧾 Original Method Name:\", original_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:00:10.896824Z","iopub.execute_input":"2025-04-04T20:00:10.897199Z","iopub.status.idle":"2025-04-04T20:00:10.903143Z","shell.execute_reply.started":"2025-04-04T20:00:10.897165Z","shell.execute_reply":"2025-04-04T20:00:10.902084Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"if debug:\n    # Show sample\n    \n    print(tokenized_dataset[\"train\"][0])\n    print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n    \n    print(tokenized_dataset[\"train\"][0])\n    print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n    \n    \n    sample_index = 0 \n    \n    # From original dataset (before masking)\n    original_func_name = combined_dataset[\"train\"][sample_index][\"func_name\"]\n    print(\"Full Function Name:\", original_func_name)\n    \n    # From label inside tokenized dataset\n    label_ids = tokenized_dataset[\"train\"][sample_index][\"labels\"]\n    label_text = tokenizer.decode([id for id in label_ids if id != tokenizer.pad_token_id], skip_special_tokens=True)\n    print(\"Target Label Text (after masking & preprocessing):\", label_text)\n    \n    label_ids = tokenized_dataset['train'][0]['labels']\n    label_text = tokenizer.decode([id for id in label_ids if id != tokenizer.pad_token_id], skip_special_tokens=True)\n    print(\"Decoded Label (method name):\", label_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:00:14.605541Z","iopub.execute_input":"2025-04-04T20:00:14.605869Z","iopub.status.idle":"2025-04-04T20:00:14.611445Z","shell.execute_reply.started":"2025-04-04T20:00:14.605839Z","shell.execute_reply":"2025-04-04T20:00:14.610676Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# W&B","metadata":{}},{"cell_type":"markdown","source":"#### Make all changes to hyper-params here, pls do not change elsewhere","metadata":{}},{"cell_type":"code","source":"if debug:\n    config = {\n        \"learning_rate\": 5e-5,\n        \"batch_size\": 8,\n        \"num_train_epochs\": 1,\n        \"eval_steps\": 20,\n        \"save_steps\": 20,\n        \"save_total_limit\": 1,\n        \"logging_steps\": 10,\n        \"fp16\": False,  # for smoke-test\n        \"predict_with_generate\": True,\n        \"load_best_model_at_end\": True,\n        \"evaluation_strategy\": \"steps\",\n        \"logging_strategy\": \"steps\",\n        \"save_strategy\": \"steps\",\n        \"output_dir\": \"./debug_results\",\n        \"report_to\": \"wandb\",\n        \"run_name\": \"mngast120k_smoke_test\",\n        \"model_name\": \"Salesforce/codet5-base\"\n    }\nelse:\n    # Define hyperparameters in a dictionary\n    config = {\n        \"learning_rate\": 6e-5,\n        \"batch_size\": 8,\n        \"num_train_epochs\": 5,\n        \"eval_steps\": 2500,\n        \"save_steps\": 2500,\n        \"save_total_limit\": 3,\n        \"logging_steps\": 100,\n        #\"weight_decay\": 0.01,\n        \"fp16\": True,\n        \"predict_with_generate\": True,\n        \"load_best_model_at_end\": True,\n        \"evaluation_strategy\": \"steps\",\n        \"logging_strategy\": \"steps\",\n        \"save_strategy\": \"steps\",\n        \"output_dir\": \"./training_results\",\n        \"report_to\": \"wandb\",\n        \"run_name\": \"mngast120k_training\",\n        \"model_name\": \"Salesforce/codet5-base\"\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:00:18.795183Z","iopub.execute_input":"2025-04-04T20:00:18.795500Z","iopub.status.idle":"2025-04-04T20:00:18.801057Z","shell.execute_reply.started":"2025-04-04T20:00:18.795478Z","shell.execute_reply":"2025-04-04T20:00:18.800123Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Log hyperparameters to W&B\nwandb.login(key=\"a57462a99faeaf50d607f689b3eb0f9271926f41\")\nwandb.init(project=\"Method Name Prediction\", name=\"mng_training\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:07.562106Z","iopub.execute_input":"2025-04-04T20:01:07.562479Z","iopub.status.idle":"2025-04-04T20:01:07.583437Z","shell.execute_reply.started":"2025-04-04T20:01:07.562451Z","shell.execute_reply":"2025-04-04T20:01:07.582625Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/adigirish02-dalhousie-university/Method%20Name%20Prediction/runs/o5pwzz21?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a9634944400>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"wandb.config.update(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:14.041968Z","iopub.execute_input":"2025-04-04T20:01:14.042358Z","iopub.status.idle":"2025-04-04T20:01:14.048821Z","shell.execute_reply.started":"2025-04-04T20:01:14.042327Z","shell.execute_reply":"2025-04-04T20:01:14.048110Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Model Loading","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(config[\"model_name\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:17.454925Z","iopub.execute_input":"2025-04-04T20:01:17.455281Z","iopub.status.idle":"2025-04-04T20:01:22.398173Z","shell.execute_reply.started":"2025-04-04T20:01:17.455255Z","shell.execute_reply":"2025-04-04T20:01:22.397038Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ee8f81f8d3647aa89ac111ec440cff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"180fbf09129c4978bb10eaf59ab48dee"}},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## LoRA - Fine tuning","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\n        # Encoder attention part\n        \"q\", \"k\", \"v\", \"o\",\n        # Decoder attention part\n        \"decoder.q\", \"decoder.k\", \"decoder.v\", \"decoder.o\",\n        # Feed-forward network layers\n        \"wi\", \"wo\",\n    ],\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM,\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:25.818768Z","iopub.execute_input":"2025-04-04T20:01:25.819104Z","iopub.status.idle":"2025-04-04T20:01:26.088807Z","shell.execute_reply.started":"2025-04-04T20:01:25.819076Z","shell.execute_reply":"2025-04-04T20:01:26.088149Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"Use the code block below only if you have an input directory to load a previous checkpoint in the input tab (pls follow the file path metnioned in the checkpoint_dir variable and change the file name to your checkpoint).","metadata":{}},{"cell_type":"code","source":"# checkpoint_dir = \"/kaggle/input/checkpoint-path/training_results/checkpoint-25000\"\n# model.load_adapter(checkpoint_dir, adapter_name=\"default\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Params","metadata":{}},{"cell_type":"code","source":"cnfg = wandb.config\n\n# All fields called from config dictionary\ntraining_args = Seq2SeqTrainingArguments(\n    learning_rate=cnfg.learning_rate,\n    per_device_train_batch_size=cnfg.batch_size,\n    per_device_eval_batch_size=cnfg.batch_size,\n    num_train_epochs=cnfg.num_train_epochs,\n    eval_steps=cnfg.eval_steps,\n    save_steps=cnfg.save_steps,\n    save_total_limit=cnfg.save_total_limit,\n    logging_steps=cnfg.logging_steps,\n    # weight_decay=cnfg.weight_decay,\n    fp16=cnfg.fp16,\n    predict_with_generate=cnfg.predict_with_generate,\n    load_best_model_at_end=cnfg.load_best_model_at_end,\n    eval_strategy=cnfg.evaluation_strategy,\n    logging_strategy=cnfg.logging_strategy,\n    save_strategy=cnfg.save_strategy,\n    output_dir=cnfg.output_dir,\n    report_to=cnfg.report_to,\n    run_name=cnfg.run_name,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:31.186810Z","iopub.execute_input":"2025-04-04T20:01:31.187140Z","iopub.status.idle":"2025-04-04T20:01:31.310145Z","shell.execute_reply.started":"2025-04-04T20:01:31.187095Z","shell.execute_reply":"2025-04-04T20:01:31.309473Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    processing_class=tokenizer,\n    data_collator=collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:40.845237Z","iopub.execute_input":"2025-04-04T20:01:40.845545Z","iopub.status.idle":"2025-04-04T20:01:41.416593Z","shell.execute_reply.started":"2025-04-04T20:01:40.845522Z","shell.execute_reply":"2025-04-04T20:01:41.415521Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:01:44.652765Z","iopub.execute_input":"2025-04-04T20:01:44.653104Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17564' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17564/18750 6:40:47 < 27:03, 0.73 it/s, Epoch 4.68/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2500</td>\n      <td>0.103600</td>\n      <td>0.111066</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.101400</td>\n      <td>0.111529</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.099300</td>\n      <td>0.111971</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.090300</td>\n      <td>0.113855</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.088100</td>\n      <td>0.114688</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.089400</td>\n      <td>0.115389</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.085800</td>\n      <td>0.116489</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test-output","metadata":{}},{"cell_type":"code","source":"# correct = 0\n# total = 0\n# model.eval()\n# device = model.device  # Get model's device (CPU/GPU)\n\n# # Select first 100 examples from test set\n# test_subset = tokenized_dataset[\"test\"].select(range(50))\n\n# with torch.no_grad():  # Disable gradient calculation for evaluation\n#     for example in test_subset:\n#         # Move input to same device as model\n#         input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n        \n#         # Generate prediction with more appropriate max_length\n#         generated_ids = model.generate(\n#             input_ids=input_ids,\n#             max_length=50,  # Function names are rarely >20 tokens\n#             num_beams=3,    # Better results with beam search\n#             early_stopping=True\n#         )\n        \n#         # Decode both prediction and label\n#         predicted_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True).strip()\n#         expected_text = tokenizer.decode(example[\"labels\"], skip_special_tokens=True).strip()\n\n#         # Update counts\n#         if predicted_text == expected_text:\n#             correct += 1\n#         total += 1\n\n#         print(f\"Expected: {expected_text} | Predicted: {predicted_text}\")\n\n# accuracy = correct / total\n# print(f\"\\nExact Match Accuracy on 1000 samples: {accuracy:.2%}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if test_run:\n    test_input = '''def <extra_id_0>(x, y):\n        return (x ** 2 + y ** 2) ** 0.5\n    '''\n    test_input2 = '''public static int <extra_id_0>(int n) {\n        if (n == 0) {\n            return 1;\n        }\n        return n * <extra_id_0>(n - 1);\n    }\n    '''\n    test_input3 = '''def <extra_id_0>(data, window_size=3):\n        if len(data) < window_size:\n            raise ValueError(\"Data length must be at least equal to the window size.\")\n        \n        moving_averages = []\n        for i in range(len(data) - window_size + 1):\n            window = data[i : i + window_size]\n            window_average = sum(window) / window_size\n            moving_averages.append(window_average)\n        \n        return moving_averages\n    '''\n    test_input4 = '''public static int <extra_id_0>(int[] numbers) {\n        int max = Integer.MIN_VALUE;\n        for (int num : numbers) {\n            if (num > max) {\n                max = num;\n            }\n        }\n        return max;\n    }\n    '''\n    # Tokenize (on GPU)\n    inputs = tokenizer(test_input2, return_tensors=\"pt\").to(model.device)\n    \n    # Generate\n    generated_ids = model.generate(**inputs, max_length=16)\n    \n    # Decode\n    output_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    print(\"Predicted method name:\", output_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T07:25:22.360585Z","iopub.execute_input":"2025-04-04T07:25:22.361140Z","iopub.status.idle":"2025-04-04T07:25:23.333835Z","shell.execute_reply.started":"2025-04-04T07:25:22.361103Z","shell.execute_reply":"2025-04-04T07:25:23.332781Z"}},"outputs":[{"name":"stdout","text":"Predicted method name: get_key_count(n - 1);\n           \n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"if debug:\n    !zip -r /kaggle/working/training_checkpoints.zip /kaggle/working/debug_results\nelse:\n    !zip -r /kaggle/working/training_checkpoints.zip /kaggle/working/training_results","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}