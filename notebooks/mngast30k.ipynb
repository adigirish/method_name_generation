{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:51:12.905874Z",
     "iopub.status.busy": "2025-04-04T07:51:12.905435Z",
     "iopub.status.idle": "2025-04-04T07:51:18.181415Z",
     "shell.execute_reply": "2025-04-04T07:51:18.180561Z",
     "shell.execute_reply.started": "2025-04-04T07:51:12.905810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Kaggle requirements.txt installer\n",
    "# # This script installs the packages listed in the requirements.txt file\n",
    "# !pip install -r /kaggle/input/requirements-txt/requirements.txt\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-04T07:51:20.652246Z",
     "iopub.status.busy": "2025-04-04T07:51:20.651931Z",
     "iopub.status.idle": "2025-04-04T07:51:44.984703Z",
     "shell.execute_reply": "2025-04-04T07:51:44.984071Z",
     "shell.execute_reply.started": "2025-04-04T07:51:20.652218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# WandB\n",
    "import wandb\n",
    "\n",
    "# AST\n",
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_python\n",
    "import tree_sitter_java\n",
    "\n",
    "## AST Graphing\n",
    "import graphviz\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, concatenate_datasets\n",
    "\n",
    "\n",
    "import evaluate\n",
    "\n",
    "# set to False for full training config\n",
    "debug = False\n",
    "# set tp True for enabling testing blocks\n",
    "test_run = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:52:02.085593Z",
     "iopub.status.busy": "2025-04-04T07:52:02.084981Z",
     "iopub.status.idle": "2025-04-04T07:53:46.647405Z",
     "shell.execute_reply": "2025-04-04T07:53:46.646562Z",
     "shell.execute_reply.started": "2025-04-04T07:52:02.085568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Python loading\n",
    "python_dataset = DatasetDict({\n",
    "    'train': load_dataset('code_search_net', 'python', split='train[:15000]', trust_remote_code=True),\n",
    "    'validation': load_dataset('code_search_net', 'python', split='validation[:2000]', trust_remote_code=True),\n",
    "    'test': load_dataset('code_search_net', 'python', split='test[:2000]', trust_remote_code=True)\n",
    "})\n",
    "\n",
    "python_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Java Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:54:06.709538Z",
     "iopub.status.busy": "2025-04-04T07:54:06.709231Z",
     "iopub.status.idle": "2025-04-04T07:56:00.092090Z",
     "shell.execute_reply": "2025-04-04T07:56:00.091369Z",
     "shell.execute_reply.started": "2025-04-04T07:54:06.709512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Java loading\n",
    "java_dataset = DatasetDict({\n",
    "    'train': load_dataset('code_search_net', 'java', split='train[:15000]', trust_remote_code=True),\n",
    "    'validation': load_dataset('code_search_net', 'java', split='validation[:2000]', trust_remote_code=True),\n",
    "    'test': load_dataset('code_search_net', 'java', split='test[:2000]', trust_remote_code=True)\n",
    "})\n",
    "\n",
    "java_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:56:16.270358Z",
     "iopub.status.busy": "2025-04-04T07:56:16.270050Z",
     "iopub.status.idle": "2025-04-04T07:56:17.430418Z",
     "shell.execute_reply": "2025-04-04T07:56:17.429511Z",
     "shell.execute_reply.started": "2025-04-04T07:56:16.270331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = DatasetDict({\n",
    "    'train': concatenate_datasets([python_dataset['train'], java_dataset['train']]),\n",
    "    'validation': concatenate_datasets([python_dataset['validation'], java_dataset['validation']]),\n",
    "    'test': concatenate_datasets([python_dataset['test'], java_dataset['test']])\n",
    "})\n",
    "\n",
    "if debug:\n",
    "    combined_dataset[\"train\"] = combined_dataset[\"train\"].select(range(200))\n",
    "    combined_dataset[\"validation\"] = combined_dataset[\"validation\"].select(range(50))\n",
    "    combined_dataset[\"test\"] = combined_dataset[\"test\"].select(range(50))\n",
    "\n",
    "combined_dataset['train'] = combined_dataset['train'].shuffle(seed=42)\n",
    "combined_dataset['validation'] = combined_dataset['validation'].shuffle(seed=42)\n",
    "combined_dataset['test'] = combined_dataset['test'].shuffle(seed=42)\n",
    "\n",
    "combined_dataset['train']['func_code_string'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:56:22.929626Z",
     "iopub.status.busy": "2025-04-04T07:56:22.929339Z",
     "iopub.status.idle": "2025-04-04T07:56:22.941678Z",
     "shell.execute_reply": "2025-04-04T07:56:22.941013Z",
     "shell.execute_reply.started": "2025-04-04T07:56:22.929604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the languages\n",
    "PY_LANGUAGE = Language(tree_sitter_python.language())\n",
    "JAVA_LANGUAGE = Language(tree_sitter_java.language())\n",
    "\n",
    "# Initialize the parsers by passing the language\n",
    "python_parser = Parser(PY_LANGUAGE)\n",
    "java_parser = Parser(JAVA_LANGUAGE)\n",
    "\n",
    "def parse_code_to_ast(code, language):\n",
    "    if language.lower() == 'python':\n",
    "        parser = python_parser\n",
    "    elif language.lower() == 'java':\n",
    "        parser = java_parser\n",
    "    tree = parser.parse(bytes(code, 'utf8'))\n",
    "    return tree\n",
    "\n",
    "def sbt_traverse(node):\n",
    "    \"\"\"\n",
    "    Recursively traverse the AST node using an SBT (Structure-Based Traversal) method.\n",
    "    This function outputs a list of tokens with explicit start and end markers for each node.\n",
    "    \"\"\"\n",
    "    # Add a start marker for the current node\n",
    "    sequence = [f\"<{node.type}>\"]\n",
    "    # Recursively traverse each child and extend the sequence\n",
    "    for child in node.children:\n",
    "        sequence.extend(sbt_traverse(child))\n",
    "    # Add an end marker for the current node\n",
    "    sequence.append(f\"</{node.type}>\")\n",
    "    return sequence\n",
    "\n",
    "# Visualize AST Graph\n",
    "def visualize_ast(tree):\n",
    "    dot = graphviz.Digraph(format=\"png\")\n",
    "    \n",
    "    def add_nodes_edges(node, parent_id=None):\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, label=node.type)  # Add the node with its type as label\n",
    "\n",
    "        if parent_id:\n",
    "            dot.edge(parent_id, node_id)  # Add an edge from the parent to this node\n",
    "        \n",
    "        for child in node.children:\n",
    "            add_nodes_edges(child, node_id)\n",
    "    \n",
    "    add_nodes_edges(tree.root_node)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST: AST Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:56:28.954191Z",
     "iopub.status.busy": "2025-04-04T07:56:28.953824Z",
     "iopub.status.idle": "2025-04-04T07:56:28.959657Z",
     "shell.execute_reply": "2025-04-04T07:56:28.958632Z",
     "shell.execute_reply.started": "2025-04-04T07:56:28.954163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    # Retrieve code strings from your datasets (for testing)\n",
    "    python_code = python_dataset['train']['func_code_string'][2]\n",
    "    java_code = java_dataset['train']['func_code_string'][2]\n",
    "    \n",
    "    # Parse the code to AST trees\n",
    "    python_tree = python_parser.parse(bytes(python_code, \"utf8\"))\n",
    "    java_tree = java_parser.parse(bytes(java_code, \"utf8\"))\n",
    "    \n",
    "    # Generate AST Visualization for Python code sample\n",
    "    ast_viz = visualize_ast(python_tree)\n",
    "    ast_viz.render(\"ast_visualization\", format=\"png\", view=True)\n",
    "    \n",
    "    # Print the basic AST representation\n",
    "    print(\"Python AST:\")\n",
    "    print(str(python_tree.root_node))\n",
    "    print(\"\\nJava AST:\")\n",
    "    print(str(java_tree.root_node))\n",
    "    \n",
    "    # Generate SBT sequences from the ASTs\n",
    "    python_sbt_sequence = \" \".join(sbt_traverse(python_tree.root_node))\n",
    "    java_sbt_sequence = \" \".join(sbt_traverse(java_tree.root_node))\n",
    "    \n",
    "    # Print the SBT sequences\n",
    "    print(\"\\nPython SBT Sequence:\")\n",
    "    print(python_sbt_sequence)\n",
    "    print(\"\\nJava SBT Sequence:\")\n",
    "    print(java_sbt_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AST Integration, Masking & Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:56:34.770353Z",
     "iopub.status.busy": "2025-04-04T07:56:34.770065Z",
     "iopub.status.idle": "2025-04-04T07:56:36.426825Z",
     "shell.execute_reply": "2025-04-04T07:56:36.426099Z",
     "shell.execute_reply.started": "2025-04-04T07:56:34.770334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mask_func_name(code_str: str, func_name: str, lang: str) -> str:\n",
    "    lang = lang.lower()\n",
    "\n",
    "    if lang == 'python':\n",
    "        pattern = rf\"(def\\s+)({re.escape(func_name)})(\\s*\\()\"\n",
    "        return re.sub(pattern, r\"\\1<extra_id_0>\\3\", code_str, count=1)\n",
    "    \n",
    "    elif lang == 'java':\n",
    "        pattern = rf\"(?<!\\w){re.escape(func_name)}(?=\\s*\\()\"\n",
    "        return re.sub(pattern, \"<extra_id_0>\", code_str, count=1)\n",
    "\n",
    "    else:\n",
    "        return code_str\n",
    "\n",
    "def test_real_python_samples(dataset, num_samples=3):\n",
    "    print(\"=== REAL PYTHON SAMPLES ===\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        full_func_name = dataset['train'][i]['func_name'] \n",
    "        method_name = full_func_name.split('.')[-1] \n",
    "        code = dataset['train'][i]['func_code_string']\n",
    "        \n",
    "        print(f\"--- Sample #{i} ---\")\n",
    "        print(f\"Original Function Name: {full_func_name}\")\n",
    "        print(\"\\nOriginal Code:\\n\", code)\n",
    "        print(\"\\nMasked Code:\\n\", mask_func_name(code, method_name, lang=\"python\"))\n",
    "        print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "def test_real_java_samples(dataset, num_samples=3):\n",
    "    print(\"=== REAL JAVA SAMPLES ===\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        full_func_name = dataset['train'][i]['func_name']\n",
    "        method_name = full_func_name.split('.')[-1]\n",
    "        code = dataset['train'][i]['func_code_string']\n",
    "        \n",
    "        print(f\"--- Sample #{i} ---\")\n",
    "        print(f\"Original Function Name: {full_func_name}\")\n",
    "        print(\"\\nOriginal Code:\\n\", code)\n",
    "        print(\"\\nMasked Code:\\n\", mask_func_name(code, method_name, lang=\"java\"))\n",
    "        print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(examples):\n",
    "    combined_inputs = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    # Iterate over each example\n",
    "    for code, target, lang in zip(examples['func_code_string'], examples['func_name'], examples['language']):\n",
    "         # Extract method name (in case it's fully qualified like Class.method)\n",
    "        method_name = target.split('.')[-1]\n",
    "        # Mask function name in definition\n",
    "        masked_code = mask_func_name(code, method_name, lang)\n",
    "\n",
    "        tree = parse_code_to_ast(code, lang)\n",
    "        root_node = tree.root_node\n",
    "        ast_features = sbt_traverse(root_node)\n",
    "        \n",
    "        ast_string = \"<AST> \" + \" \".join(ast_features) + \" </AST>\" # Wrapping the AST features with <AST> and </AST>.\n",
    "        combined_input = masked_code + \" \" + ast_string # Combining code with AST features\n",
    "\n",
    "        combined_inputs.append(combined_input)\n",
    "        combined_labels.append(method_name) # Extract the method name from the full path\n",
    "    \n",
    "    # Tokenize the combined input and targets\n",
    "    model_inputs = tokenizer(combined_inputs, max_length=1024, truncation=True, padding='max_length')\n",
    "    tokenized_labels = tokenizer(combined_labels, max_length=50, truncation=True, padding='max_length')\n",
    "    \n",
    "    model_inputs['labels'] = tokenized_labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "special_tokens = {\"additional_special_tokens\": [\"<AST>\", \"</AST>\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "if debug:\n",
    "    def inspect_samples(dataset, lang: str, num_samples: int = 5):\n",
    "        print(f\"\\n=== {lang.upper()} SAMPLE VERIFICATION ===\\n\")\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset['train'][i]\n",
    "            code = sample['func_code_string']\n",
    "            full_name = sample['func_name']\n",
    "            method_name = full_name.split('.')[-1]\n",
    "\n",
    "            masked_code = mask_func_name(code, method_name, lang)\n",
    "            dummy_ast = \"<AST> dummy AST </AST>\"\n",
    "            combined_input = masked_code + \" \" + dummy_ast\n",
    "            tokens = tokenizer.tokenize(combined_input)\n",
    "\n",
    "            print(f\"--- Sample #{i} ---\")\n",
    "            print(f\"Original Function Name: {full_name}\")\n",
    "            print(\"\\nOriginal Code:\\n\", code)\n",
    "            print(\"\\nMasked Code:\\n\", masked_code)\n",
    "            print(\"\\nFinal Combined Input:\\n\", combined_input)\n",
    "            print(\"\\nTokenized Input:\\n\", tokens)\n",
    "            print(\"=\" * 100)\n",
    "\n",
    "    # Run both inspections\n",
    "    inspect_samples(python_dataset, lang=\"python\", num_samples=5)\n",
    "    inspect_samples(java_dataset, lang=\"java\", num_samples=5)\n",
    "    \n",
    "    # Run the test\n",
    "    test_real_java_samples(java_dataset, num_samples=5)\n",
    "    test_real_python_samples(python_dataset, num_samples=5)\n",
    "    \n",
    "    # print(\"<mask>\" in tokenizer.get_vocab())\n",
    "    print(\"<extra_id_0>\" in tokenizer.get_vocab())\n",
    "    print(\"Token ID for <extra_id_0>:\", tokenizer.convert_tokens_to_ids(\"<extra_id_0>\"))\n",
    "    print(\"All special tokens:\", tokenizer.special_tokens_map)\n",
    "    print(\"Additional special tokens:\", tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:56:42.520112Z",
     "iopub.status.busy": "2025-04-04T07:56:42.519776Z",
     "iopub.status.idle": "2025-04-04T08:02:14.507212Z",
     "shell.execute_reply": "2025-04-04T08:02:14.506445Z",
     "shell.execute_reply.started": "2025-04-04T07:56:42.520086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = combined_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:02:26.084342Z",
     "iopub.status.busy": "2025-04-04T08:02:26.084039Z",
     "iopub.status.idle": "2025-04-04T08:02:26.089852Z",
     "shell.execute_reply": "2025-04-04T08:02:26.088929Z",
     "shell.execute_reply.started": "2025-04-04T08:02:26.084321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    num_samples_to_show = 5\n",
    "    \n",
    "    for idx in range(num_samples_to_show):\n",
    "        print(f\"\\n===== Sample {idx + 1} =====\")\n",
    "    \n",
    "        # Print decoded input (with masking, i.e., function body with <extra_id_0>)\n",
    "        input_ids = tokenized_dataset[\"train\"][idx][\"input_ids\"]\n",
    "        decoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        print(\"Masked Input Code:\\n\", decoded_input)\n",
    "    \n",
    "        # Print decoded label (method name target)\n",
    "        label_ids = tokenized_dataset[\"train\"][idx][\"labels\"]\n",
    "        decoded_label = tokenizer.decode(\n",
    "            [id for id in label_ids if id != tokenizer.pad_token_id],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        print(\"Target Method Name:\", decoded_label)\n",
    "    \n",
    "        # Optional: show original method name from combined dataset (if available)\n",
    "        if \"func_name\" in combined_dataset[\"train\"].features:\n",
    "            original_name = combined_dataset[\"train\"][idx][\"func_name\"]\n",
    "            print(\"Original Method Name:\", original_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:02:28.919220Z",
     "iopub.status.busy": "2025-04-04T08:02:28.918915Z",
     "iopub.status.idle": "2025-04-04T08:02:28.924738Z",
     "shell.execute_reply": "2025-04-04T08:02:28.923880Z",
     "shell.execute_reply.started": "2025-04-04T08:02:28.919195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    # Show sample\n",
    "    \n",
    "    print(tokenized_dataset[\"train\"][0])\n",
    "    print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n",
    "    \n",
    "    print(tokenized_dataset[\"train\"][0])\n",
    "    print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n",
    "    \n",
    "    sample_index = 0 \n",
    "    \n",
    "    # From the original dataset (before masking)\n",
    "    original_func_name = combined_dataset[\"train\"][sample_index][\"func_name\"]\n",
    "    print(\"Full Function Name:\", original_func_name)\n",
    "    \n",
    "    # From the labels inside the tokenized dataset\n",
    "    label_ids = tokenized_dataset[\"train\"][sample_index][\"labels\"]\n",
    "    label_text = tokenizer.decode([id for id in label_ids if id != tokenizer.pad_token_id], skip_special_tokens=True)\n",
    "    print(\"Target Label Text (after masking & preprocessing):\", label_text)\n",
    "    \n",
    "    label_ids = tokenized_dataset['train'][0]['labels']\n",
    "    label_text = tokenizer.decode([id for id in label_ids if id != tokenizer.pad_token_id], skip_special_tokens=True)\n",
    "    print(\"Decoded Label (func name):\", label_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make all changes to hyper-params here, pls do not change elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:03:19.184715Z",
     "iopub.status.busy": "2025-04-04T08:03:19.184366Z",
     "iopub.status.idle": "2025-04-04T08:03:19.189863Z",
     "shell.execute_reply": "2025-04-04T08:03:19.189040Z",
     "shell.execute_reply.started": "2025-04-04T08:03:19.184686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    config = {\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"eval_steps\": 20,\n",
    "        \"save_steps\": 20,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"logging_steps\": 10,\n",
    "        \"fp16\": False,  # for smoke-test\n",
    "        \"predict_with_generate\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"evaluation_strategy\": \"steps\",\n",
    "        \"logging_strategy\": \"steps\",\n",
    "        \"save_strategy\": \"steps\",\n",
    "        \"output_dir\": \"./debug_results\",\n",
    "        \"report_to\": \"wandb\",\n",
    "        \"run_name\": \"mngast120k_smoke_test\",\n",
    "        \"model_name\": \"Salesforce/codet5-base\"\n",
    "    }\n",
    "else:\n",
    "    # Define hyperparameters in a dictionary\n",
    "    config = {\n",
    "        \"learning_rate\": 6e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"num_train_epochs\": 5,\n",
    "        \"eval_steps\": 2500,\n",
    "        \"save_steps\": 2500,\n",
    "        \"save_total_limit\": 3,\n",
    "        \"logging_steps\": 100,\n",
    "        #\"weight_decay\": 0.01,\n",
    "        \"fp16\": True,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"evaluation_strategy\": \"steps\",\n",
    "        \"logging_strategy\": \"steps\",\n",
    "        \"save_strategy\": \"steps\",\n",
    "        \"output_dir\": \"./training_results\",\n",
    "        \"report_to\": \"wandb\",\n",
    "        \"run_name\": \"mngast120k_training\",\n",
    "        \"model_name\": \"Salesforce/codet5-base\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:03:23.112827Z",
     "iopub.status.busy": "2025-04-04T08:03:23.112499Z",
     "iopub.status.idle": "2025-04-04T08:03:36.803870Z",
     "shell.execute_reply": "2025-04-04T08:03:36.803156Z",
     "shell.execute_reply.started": "2025-04-04T08:03:23.112799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Log hyperparameters to W&B\n",
    "wandb.login(key=\"ebd5969438c4d7fbf09289ce11c991e89fcc3b5b\")\n",
    "wandb.init(project=\"Method Name Prediction\", name=\"mng_training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:03:51.842477Z",
     "iopub.status.busy": "2025-04-04T08:03:51.842189Z",
     "iopub.status.idle": "2025-04-04T08:03:51.848237Z",
     "shell.execute_reply": "2025-04-04T08:03:51.847453Z",
     "shell.execute_reply.started": "2025-04-04T08:03:51.842455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:04:01.962518Z",
     "iopub.status.busy": "2025-04-04T08:04:01.962199Z",
     "iopub.status.idle": "2025-04-04T08:04:07.581672Z",
     "shell.execute_reply": "2025-04-04T08:04:07.580499Z",
     "shell.execute_reply.started": "2025-04-04T08:04:01.962491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "# Accounting for additional <AST> special tokens\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA - Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:04:22.507860Z",
     "iopub.status.busy": "2025-04-04T08:04:22.507508Z",
     "iopub.status.idle": "2025-04-04T08:04:23.151620Z",
     "shell.execute_reply": "2025-04-04T08:04:23.150977Z",
     "shell.execute_reply.started": "2025-04-04T08:04:22.507816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        # Encoder attention part\n",
    "        \"q\", \"k\", \"v\", \"o\",\n",
    "        # Decoder attention part\n",
    "        \"decoder.q\", \"decoder.k\", \"decoder.v\", \"decoder.o\",\n",
    "        # Feed-forward network layers\n",
    "        \"wi\", \"wo\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:04:41.950696Z",
     "iopub.status.busy": "2025-04-04T08:04:41.950394Z",
     "iopub.status.idle": "2025-04-04T08:04:44.575382Z",
     "shell.execute_reply": "2025-04-04T08:04:44.574676Z",
     "shell.execute_reply.started": "2025-04-04T08:04:41.950674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# \"/kaggle/input/checkpoint-path/training_results/checkpoint-25000\"\n",
    "checkpoint_dir = \"training_results/mngast120k/adapters25000\"\n",
    "model.load_adapter(checkpoint_dir, adapter_name=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:04:53.758456Z",
     "iopub.status.busy": "2025-04-04T08:04:53.758164Z",
     "iopub.status.idle": "2025-04-04T08:04:53.790563Z",
     "shell.execute_reply": "2025-04-04T08:04:53.789918Z",
     "shell.execute_reply.started": "2025-04-04T08:04:53.758434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cnfg = wandb.config\n",
    "\n",
    "# All fields called from config dictionary\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    learning_rate=cnfg.learning_rate,\n",
    "    per_device_train_batch_size=cnfg.batch_size,\n",
    "    per_device_eval_batch_size=cnfg.batch_size,\n",
    "    num_train_epochs=cnfg.num_train_epochs,\n",
    "    eval_steps=cnfg.eval_steps,\n",
    "    save_steps=cnfg.save_steps,\n",
    "    save_total_limit=cnfg.save_total_limit,\n",
    "    logging_steps=cnfg.logging_steps,\n",
    "    # weight_decay=cnfg.weight_decay,\n",
    "    fp16=cnfg.fp16,\n",
    "    predict_with_generate=cnfg.predict_with_generate,\n",
    "    load_best_model_at_end=cnfg.load_best_model_at_end,\n",
    "    eval_strategy=cnfg.evaluation_strategy,\n",
    "    logging_strategy=cnfg.logging_strategy,\n",
    "    save_strategy=cnfg.save_strategy,\n",
    "    output_dir=cnfg.output_dir,\n",
    "    report_to=cnfg.report_to,\n",
    "    run_name=cnfg.run_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:05:01.052654Z",
     "iopub.status.busy": "2025-04-04T08:05:01.052355Z",
     "iopub.status.idle": "2025-04-04T08:05:01.416561Z",
     "shell.execute_reply": "2025-04-04T08:05:01.415702Z",
     "shell.execute_reply.started": "2025-04-04T08:05:01.052630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:05:20.325263Z",
     "iopub.status.busy": "2025-04-04T08:05:20.324891Z",
     "iopub.status.idle": "2025-04-04T08:06:19.928172Z",
     "shell.execute_reply": "2025-04-04T08:06:19.926948Z",
     "shell.execute_reply.started": "2025-04-04T08:05:20.325235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Evaluate on a small subset for speed (adjust as needed)\n",
    "eval_samples = 100\n",
    "model.eval()\n",
    "device = model.device\n",
    "predictions, references = [], []\n",
    "exact_matches = 0\n",
    "\n",
    "test_subset = tokenized_dataset[\"test\"].select(range(eval_samples))\n",
    "\n",
    "for example in tqdm(test_subset):\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=50,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True).strip()\n",
    "    ref = tokenizer.decode(example[\"labels\"], skip_special_tokens=True).strip()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(ref)\n",
    "\n",
    "    if pred == ref:\n",
    "        exact_matches += 1\n",
    "\n",
    "# ROUGE\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"ROUGE scores:\")\n",
    "for k, v in rouge_result.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# BLEU\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[r] for r in references])\n",
    "print(f\"\\nBLEU score: {bleu_result['bleu']:.4f}\")\n",
    "\n",
    "# METEOR\n",
    "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "print(f\"\\nMETEOR score: {meteor_result['meteor']:.4f}\")\n",
    "\n",
    "# Accuracy (exact match)\n",
    "exact_match_accuracy = exact_matches / eval_samples\n",
    "print(f\"\\nExact Match Accuracy: {exact_match_accuracy:.4f}\")\n",
    "\n",
    "# Perplexity\n",
    "def calculate_perplexity(model, tokenizer, examples):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for example in tqdm(examples, desc=\"Perplexity\"):\n",
    "        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "        labels = torch.tensor(example[\"labels\"]).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, labels=labels)\n",
    "            loss = output.loss\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    return np.exp(avg_loss)\n",
    "\n",
    "perplexity = calculate_perplexity(model, tokenizer, test_subset)\n",
    "print(f\"\\nPerplexity: {perplexity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:25:22.361140Z",
     "iopub.status.busy": "2025-04-04T07:25:22.360585Z",
     "iopub.status.idle": "2025-04-04T07:25:23.333835Z",
     "shell.execute_reply": "2025-04-04T07:25:23.332781Z",
     "shell.execute_reply.started": "2025-04-04T07:25:22.361103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if test_run:\n",
    "    test_input = '''def <extra_id_0>(x, y):\n",
    "        return (x ** 2 + y ** 2) ** 0.5\n",
    "    '''\n",
    "    test_input2 = '''public static int <extra_id_0>(int n) {\n",
    "        if (n == 0) {\n",
    "            return 1;\n",
    "        }\n",
    "        return n * <extra_id_0>(n - 1);\n",
    "    }\n",
    "    '''\n",
    "    test_input3 = '''def <extra_id_0>(data, window_size=3):\n",
    "        if len(data) < window_size:\n",
    "            raise ValueError(\"Data length must be at least equal to the window size.\")\n",
    "        \n",
    "        moving_averages = []\n",
    "        for i in range(len(data) - window_size + 1):\n",
    "            window = data[i : i + window_size]\n",
    "            window_average = sum(window) / window_size\n",
    "            moving_averages.append(window_average)\n",
    "        \n",
    "        return moving_averages\n",
    "    '''\n",
    "    test_input4 = '''public static int <extra_id_0>(int[] numbers) {\n",
    "        int max = Integer.MIN_VALUE;\n",
    "        for (int num : numbers) {\n",
    "            if (num > max) {\n",
    "                max = num;\n",
    "            }\n",
    "        }\n",
    "        return max;\n",
    "    }\n",
    "    '''\n",
    "    # Tokenize (on GPU)\n",
    "    inputs = tokenizer(test_input2, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate\n",
    "    generated_ids = model.generate(**inputs, max_length=16)\n",
    "    \n",
    "    # Decode\n",
    "    output_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(\"Predicted method name:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    !zip -r /kaggle/working/training_checkpoints.zip /kaggle/working/debug_results\n",
    "else:\n",
    "    !zip -r /kaggle/working/training_checkpoints.zip /kaggle/working/training_results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6998284,
     "sourceId": 11230273,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mng_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
